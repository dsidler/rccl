diff --git a/apps/nccl/src/allreduce.hpp b/apps/nccl/src/allreduce.hpp
index 1cd7f30..2831bba 100644
--- a/apps/nccl/src/allreduce.hpp
+++ b/apps/nccl/src/allreduce.hpp
@@ -448,16 +448,16 @@ cudaError_t allreduce(T* buff, T* scratch, T* resultBuff, mscclpp::DeviceHandle<
   static uint32_t flag = 1;
 
   if (sizeof(T) * nelems < worldSize * sizeof(int)) {
-    int nBlocks = 7;
+    int nBlocks = (nRanksPerNode - 1);
     int nThreadsPerBlock = 32;
     allreduceAllToAll<<<nBlocks, nThreadsPerBlock, 0, stream>>>(buff, scratch, resultBuff, smChannels, channelInOffset,
                                                                 channelScratchOffset, rank, nRanksPerNode, worldSize,
                                                                 nelems, flag++);
   } else if (sizeof(T) * nelems <= (1 << 20)) {
-    int nBlocks = 28;
+    int nBlocks = 4 * (nRanksPerNode - 1);
     int nThreadsPerBlock = 1024;
     if (nelems >= 8192) {
-      nBlocks = 56;
+      nBlocks = 8 * (nRanksPerNode - 1);
       nThreadsPerBlock = (nelems <= 76800) ? 512 : 1024;
     }
     allreduce7<<<nBlocks, nThreadsPerBlock, 0, stream>>>(buff, scratch, resultBuff, smChannels, channelInOffset,
diff --git a/apps/nccl/src/common.hpp b/apps/nccl/src/common.hpp
index 015e0a2..af723d4 100644
--- a/apps/nccl/src/common.hpp
+++ b/apps/nccl/src/common.hpp
@@ -13,10 +13,10 @@
 #define WARP_SIZE 32
 #endif
 
-constexpr int NRANKS_PER_NODE = 8;
-constexpr int NPEERS = 7;
+constexpr int NRANKS_PER_NODE = 64;
+constexpr int NPEERS = NRANKS_PER_NODE - 1;
 
-constexpr int SCRATCH_SIZE = 2 * 1024 * 1024 * 70;  // double buffer * 35 thread-blocks * 8 ranks * 256KB = 70MB
+constexpr int SCRATCH_SIZE = 2 * 35 * NRANKS_PER_NODE * 256 * 1024; // double buffer * 35 thread-blocks * NUM_RANKS * 256KB
 
 __device__ mscclpp::DeviceSyncer deviceSyncer;
 
